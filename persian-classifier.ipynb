{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xwMIIn6umaYPxoh4_XAS1ydFBPNyQBSr",
      "authorship_tag": "ABX9TyMT1SyGYgBq0/JXqI73S3UZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/q010p/persian-text-classifier/blob/main/persian-classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMQKZV-yMfAW"
      },
      "source": [
        "**Download dataset from [this](https://drive.google.com/file/d/1Re3OYrevmlMscyNSBsDeIdX2xfndnM7C/view?usp=sharing) link and read it using Pandas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtOdVaAeBhDx"
      },
      "source": [
        "! pip install hazm\n",
        "! pip install pandas\n",
        "! pip install sklearn\n",
        "! pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkiX3MACChCZ"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_V1Y3VDCjrT"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLX-oic2OdVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081e62ea-100e-49c6-cd43-db8b7aaa9692"
      },
      "source": [
        "train_ds_path = 'train.csv'\n",
        "print('Reading train dataset from', train_ds_path)\n",
        "dataset = pd.read_csv(train_ds_path, index_col=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading train dataset from train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT1tJDgcrz0M"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYa_rRrXr7Ad"
      },
      "source": [
        "A function for printing Progress Bar\n",
        "Thanks to [Greenstick](https://stackoverflow.com/a/34325723)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx0ISXNtr16J"
      },
      "source": [
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = ' ')\n",
        "    # Print New Line on Complete\n",
        "    if iteration == total: \n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECOEAZwsDrHn"
      },
      "source": [
        "# **Some visualization on dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "NJNHiQiMSvcQ",
        "outputId": "9c83b6b2-49da-487c-908c-ceddbab5f2da"
      },
      "source": [
        "dataset.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nخبرنامه دانشگاه علم و صنعت ايران \\nشماره ياز...</td>\n",
              "      <td>Science and Culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nتا پايان سال 1378 دهها زمين فوتبال و \\nسالن ...</td>\n",
              "      <td>Sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nانجمن توليدكنندگان تجهيزات صنعت نفت تشكيل شد...</td>\n",
              "      <td>Economy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text             Category\n",
              "0  \\nخبرنامه دانشگاه علم و صنعت ايران \\nشماره ياز...  Science and Culture\n",
              "1  \\nتا پايان سال 1378 دهها زمين فوتبال و \\nسالن ...                Sport\n",
              "2  \\nانجمن توليدكنندگان تجهيزات صنعت نفت تشكيل شد...              Economy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0jcvPKpDVs7"
      },
      "source": [
        "TEXT_COL_NAME = 'Text'\n",
        "CAT_COL_NAME = 'Category'\n",
        "def print_row(index):\n",
        "    print('row ', index)\n",
        "    print(CAT_COL_NAME + ':', dataset.at[index, CAT_COL_NAME])\n",
        "    print(TEXT_COL_NAME + ':', dataset.at[index, TEXT_COL_NAME])\n",
        "print('Dataset Size: ', len(dataset))\n",
        "#print_row(50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFfeNhub6fGs"
      },
      "source": [
        "def get_words_set(ds):\n",
        "  _set = set()\n",
        "  for index, row in ds.iterrows():\n",
        "      if type(row[TEXT_COL_NAME]) is str:\n",
        "          _text_arr = row[TEXT_COL_NAME].split(' ')\n",
        "      else:\n",
        "          _text_arr = row[TEXT_COL_NAME]\n",
        "      _set.update(_text_arr)\n",
        "      printProgressBar(index + 1, len(ds), prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "  return _set\n",
        "\n",
        "def number_of_words(ds):\n",
        "    return len(get_words_set(ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQB-TaWjPWlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d55ff30-bf74-4fb6-bdb6-0c8ccebf50c4"
      },
      "source": [
        "print('Extracting number of words before preprocessing...')\n",
        "print('Number of words before preprocessing: ', number_of_words(dataset))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting number of words before preprocessing...\n",
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete \n",
            "Number of words before preprocessing:  782039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZVkhjXKPNnP"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWxS2eJKCRdi"
      },
      "source": [
        "**Create a list of categories and convert categories to numbers in dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t58jnBCPB75U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a5635d-97c6-479f-9b08-73ff383b2cb8"
      },
      "source": [
        "def get_categories(ds):\n",
        "  _set = set()\n",
        "  for index, row in ds.iterrows():\n",
        "      _set.add(row[CAT_COL_NAME])\n",
        "  return _set\n",
        "\n",
        "print('Extracting Category names from dataset')\n",
        "cats_vector = list(get_categories(dataset))\n",
        "\n",
        "def convert_category_to_number(cat):\n",
        "  return cats_vector.index(cat)\n",
        "\n",
        "def convert_number_to_category(index):\n",
        "  return cats_vector[index]\n",
        "\n",
        "print('Converting Category names to numbers')\n",
        "dataset[CAT_COL_NAME] = dataset.apply(lambda row:  convert_category_to_number(row[CAT_COL_NAME]), axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting Category names from dataset\n",
            "Converting Category names to numbers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "FxDCP_jxg6Hk",
        "outputId": "28d787ff-556c-422d-bb40-31c7fa702bc5"
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nخبرنامه دانشگاه علم و صنعت ايران \\nشماره ياز...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nتا پايان سال 1378 دهها زمين فوتبال و \\nسالن ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nانجمن توليدكنندگان تجهيزات صنعت نفت تشكيل شد...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nكرتين براي سومين بار نخست وزير كانادا \\nشد \\...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nخداحافظ رفقا \\nنمايندگان اروپاي شرقي در جام ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Category\n",
              "0  \\nخبرنامه دانشگاه علم و صنعت ايران \\nشماره ياز...         5\n",
              "1  \\nتا پايان سال 1378 دهها زمين فوتبال و \\nسالن ...         1\n",
              "2  \\nانجمن توليدكنندگان تجهيزات صنعت نفت تشكيل شد...        28\n",
              "3  \\nكرتين براي سومين بار نخست وزير كانادا \\nشد \\...         4\n",
              "4  \\nخداحافظ رفقا \\nنمايندگان اروپاي شرقي در جام ...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU3S7T3QSKt6"
      },
      "source": [
        "**Remove special chars and persian stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD3CAnsEPTvT"
      },
      "source": [
        "from hazm import *\n",
        "import numpy as np\n",
        "\n",
        "normalizer = Normalizer()\n",
        "\n",
        "def get_specific_chars():\n",
        "  f = open('chars.txt', 'r')\n",
        "  _tmp = f.read().split('\\n')\n",
        "  _tmp.append('\\n')\n",
        "  return _tmp\n",
        "sp_chars = get_specific_chars()\n",
        "\n",
        "def get_stop_words():\n",
        "  f = open('stop-words.txt', 'r')\n",
        "  _tmp = f.read().split('\\n')\n",
        "  for _stop in _tmp:\n",
        "    if _stop.find('ی') != -1:\n",
        "      _tmp.append(_stop.replace('ی', 'ي'))\n",
        "  return _tmp\n",
        "stop_words = get_stop_words()\n",
        "\n",
        "def remove_consecutive_spaces(text):\n",
        "  import re\n",
        "  _text = re.sub(' +', ' ', text)\n",
        "  while _text[0] == ' ':\n",
        "    _text = _text[1:]\n",
        "  while _text[len(_text)-1] == ' ':\n",
        "    _text = _text[:len(_text)-1]\n",
        "  return _text\n",
        "\n",
        "def remove_specific_chars(text, sp_chars):\n",
        "  _text = text\n",
        "  for sp_char in sp_chars:\n",
        "    _text = _text.replace(sp_char, ' ')\n",
        "    _text = remove_consecutive_spaces(_text)\n",
        "  return _text\n",
        "\n",
        "def remove_stop_words(text, stop_words):\n",
        "  _splited = text.split(' ')\n",
        "  _res = np.array(_splited)[np.in1d(_splited, stop_words, invert = True)]\n",
        "  return _res\n",
        "\n",
        "def remove_specific_chars_and_stop_words(text, sp_chars, stop_words):\n",
        "  _tmp = remove_specific_chars(text, sp_chars)\n",
        "  _tmp = remove_stop_words(_tmp, stop_words)\n",
        "  _tmp = ' '.join(_tmp)\n",
        "  _tmp = normalizer.normalize(_tmp)\n",
        "  return _tmp\n",
        "\n",
        "\n",
        "def remove_specific_chars_and_stop_words_with_pb(text, sp_chars, stop_words, index, total): \n",
        "  printProgressBar(index + 1, total, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "  _tmp = remove_specific_chars_and_stop_words(text, sp_chars, stop_words)\n",
        "  return _tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5brRAHivlHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63c37ac-1f30-409d-90f0-4b81aadb9ad7"
      },
      "source": [
        "print('Normalizing texts in dataset')\n",
        "dataset[TEXT_COL_NAME] = dataset.apply(lambda row:  remove_specific_chars_and_stop_words_with_pb(row[TEXT_COL_NAME], sp_chars, stop_words, row.name, len(dataset[TEXT_COL_NAME])), axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRZ-65XPRtT5",
        "outputId": "02692fa5-095b-4824-80de-971e813e5c32"
      },
      "source": [
        "print('Extracting number of words after preprocessing...')\n",
        "print('Number of words after removing special characters and stop words:', number_of_words(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting number of words after preprocessing...\n",
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete \n",
            "Number of words after removing special characters and stop words: 429421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TYrncJ5E8Lg"
      },
      "source": [
        "# **splitting data and vectorization using TF-IDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR1gz3HBFMSh"
      },
      "source": [
        "Spliting data to X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBM-TT7JpZdE"
      },
      "source": [
        "X = dataset.iloc[:, 0].values\n",
        "Y = dataset.iloc[:, 1:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GLJ9D65Fw9w"
      },
      "source": [
        "Vectorization Texts using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d7vgjMLxyyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b66b987-1920-4b55-d274-9c5af92ea8bd"
      },
      "source": [
        "# Building a TF IDF matrix out of the corpus of reviews\n",
        "print('Vectorizing using TF-IDF...')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorizing using TF-IDF...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9hD7e2wFl6N"
      },
      "source": [
        "Split dataset to test and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adF_4-05jzAD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtdSayL5GvS1"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atIysJcqG6qM"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        " \n",
        "def calc_accuracy(y_test, y_pred):\n",
        "  return accuracy_score(y_test, y_pred) * 100\n",
        " \n",
        "def print_accuracy(y_test, y_pred):\n",
        "  print(f\"Accuracy Score -> {calc_accuracy(y_test, y_pred)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgT_eDMWD3IV"
      },
      "source": [
        "## Classification using KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrcU4G0O-amS"
      },
      "source": [
        "#from sklearn.neighbors import KNeighborsClassifier\n",
        "#KNN_clf = KNeighborsClassifier(n_neighbors=8)\n",
        "#KNN_clf.fit(X_train, y_train)\n",
        "#y_pred = KNN_clf.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdT2RXS-AfLs"
      },
      "source": [
        "#print_accuracy(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyTtevxoGSQ4"
      },
      "source": [
        "## Classification using Multinomial NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g5LMSlYHxIq",
        "outputId": "61280166-0268-4647-9657-27fbdfdd66c9"
      },
      "source": [
        "print('Classification using Multinomial NB')\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "MNB_clf = MultinomialNB()\n",
        "MNB_clf.fit(X_train, y_train)\n",
        " \n",
        "y_pred = MNB_clf.predict(X_test)\n",
        "print_accuracy(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification using Multinomial NB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score -> 56.77215189873418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axPy43TiEKBm"
      },
      "source": [
        "## Classification using SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGRONno4C4Sr",
        "outputId": "33788321-b663-47dc-86e7-a530e30d8f7d"
      },
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        " \n",
        "print('Classification using SVM')\n",
        "SVC_model = LinearSVC(C=1, max_iter=20000, verbose=1)\n",
        "SVC_clf = CalibratedClassifierCV(SVC_model, method='sigmoid', cv=5)\n",
        "SVC_clf.fit(X_train, y_train)\n",
        "y_pred = SVC_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification using SVM\n",
            "[LibLinear]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAmBReyWIJjM",
        "outputId": "c7754b5a-5d5b-4145-b1e1-f03e44994891"
      },
      "source": [
        "print_accuracy(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score -> 79.62358427714857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "bV9b2qc6cQEn",
        "outputId": "2670b6fe-6db2-477a-ea29-c05c217f364a"
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>خبرنامه دانشگاه علم صنعت ایران شماره یازدهم خب...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>پایان دهها زمین فوتبال سالن ورزش کارگران پایان...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>انجمن تولیدکنندگان تجهیزات صنعت نفت تشکیل مجمع...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>کرتین سومین وزیر کانادا ژان کرتین وزیر کانادا ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>خداحافظ رفقا نمایندگان اروپای شرقی جام بابک کم...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Category\n",
              "0  خبرنامه دانشگاه علم صنعت ایران شماره یازدهم خب...         5\n",
              "1  پایان دهها زمین فوتبال سالن ورزش کارگران پایان...         1\n",
              "2  انجمن تولیدکنندگان تجهیزات صنعت نفت تشکیل مجمع...        28\n",
              "3  کرتین سومین وزیر کانادا ژان کرتین وزیر کانادا ...         4\n",
              "4  خداحافظ رفقا نمایندگان اروپای شرقی جام بابک کم...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpMKGqkeTwlk"
      },
      "source": [
        "# Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37dL-JqmeU4U"
      },
      "source": [
        "def predict_test(test_path):\n",
        "  print('Read test file from', test_path)\n",
        "  kaggle_test_dataset = pd.read_csv(test_path, index_col=0)\n",
        "  print('Normalizing test texts', test_path)\n",
        "  kaggle_test_dataset[TEXT_COL_NAME] = kaggle_test_dataset.apply(lambda row:  remove_specific_chars_and_stop_words_with_pb(row[TEXT_COL_NAME], sp_chars, stop_words, row.name, len(kaggle_test_dataset[TEXT_COL_NAME])), axis = 1)\n",
        "  print('split texts to kaggle_X_test')\n",
        "  kaggle_X_test = kaggle_test_dataset.iloc[:, 0].values\n",
        "  print('Vectorizing kaggle_X_test')\n",
        "  kaggle_X_test = vectorizer.transform(kaggle_X_test)\n",
        "  print('Predicting kaggle_X_test using SVC classifier')\n",
        "  kaggle_predict = SVC_clf.predict(kaggle_X_test)\n",
        "  kaggle_predict_cat = ['']*len(kaggle_predict)\n",
        "  print('Replacing predicted categories indexes to Category names')\n",
        "  for i, cat_num in enumerate(kaggle_predict):\n",
        "    kaggle_predict_cat[i] = convert_number_to_category(cat_num)\n",
        "  print('Getting output from predicted categories')\n",
        "  kaggle_test_result = kaggle_test_dataset.copy()\n",
        "  kaggle_test_result[CAT_COL_NAME] = kaggle_predict_cat\n",
        "  kaggle_test_result = kaggle_test_result.drop(columns = [TEXT_COL_NAME])\n",
        "  kaggle_test_result.head(5)\n",
        "  kaggle_test_result.to_csv('out.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ACte_jf9F3",
        "outputId": "35aa90d0-0fb8-4f08-936e-2883614c91ac"
      },
      "source": [
        "predict_test('test.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read test file from test.csv\n",
            "Normalizing test texts test.csv\n",
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete \n",
            "split texts to kaggle_X_test\n",
            "Vectorizing kaggle_X_test\n",
            "Predicting kaggle_X_test using SVC classifier\n",
            "Replacing predicted categories indexes to Category names\n",
            "Getting output from predicted categories\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}